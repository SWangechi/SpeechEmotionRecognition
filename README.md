# VibeCheckAI â€“ Giving Your Voice a Quick Mood Check ðŸŽµ

VibeCheckAI is an **AI-powered Speech Emotion Recognition** application that analyzes **human emotions** from speech.

## ðŸš€ Features
- **Real-time Speech Emotion Detection**
- **FastAPI Backend** for ML model processing
- **Streamlit UI** for an engaging user experience
- **XGBoost Model** for accurate predictions

  Interact with this application on : https://swangechi-speechemotionrecognition-frontendapp-fhxkx6.streamlit.app/

## ðŸ›  Installation
1. Clone this repository: https://github.com/SWangechi/SpeechEmotionRecognition.git

Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech. 
This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon that animals like dogs and horses employ to be able to understand human emotion.

Why we need it?
Emotion recognition is the part of speech recognition which is gaining more popularity and need for it increases enormously. 
Although there are methods to recognize emotion using machine learning techniques, this project attempts to use deep learning to recognize the emotions from data.

SER(Speech Emotion Recognition) is used in call center for classifying calls according to emotions and can be used as the performance parameter for conversational analysis thus identifying the unsatisfied customer, customer satisfaction and so on.. for helping companies improving their services

It can also be used in-car board system based on information of the mental state of the driver can be provided to the system to initiate his/her safety preventing accidents to happen

Datasets used in this project:
Crowd-sourced Emotional Multimodal Actors Dataset (Crema-D)
Ryerson Audio-Visual Database of Emotional Speech and Song (Ravdess)
Surrey Audio-Visual Expressed Emotion (Savee)
Toronto emotional speech set (Tess)
